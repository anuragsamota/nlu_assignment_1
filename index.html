<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<title>Sports vs Politics Classifier</title>
		<link rel="preconnect" href="https://fonts.googleapis.com" />
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
		<link
			href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@400;500;600&family=IBM+Plex+Serif:wght@500;600&display=swap"
			rel="stylesheet"
		/>
		<style>
			:root {
				--bg: #f6f5f1;
				--card: #ffffff;
				--text: #1a1b1e;
				--muted: #5b6068;
				--line: #e1e3e6;
				--accent: #1f4b5a;
			}

			* {
				box-sizing: border-box;
			}

			body {
				margin: 0;
				font-family: "IBM Plex Sans", sans-serif;
				color: var(--text);
				background: linear-gradient(180deg, #f6f5f1 0%, #ffffff 100%);
			}

			.page {
				max-width: 960px;
				margin: 0 auto;
				padding: 56px 20px 72px;
			}

			header {
				border-bottom: 1px solid var(--line);
				padding-bottom: 24px;
				margin-bottom: 32px;
			}

			h1 {
				font-family: "IBM Plex Serif", serif;
				font-size: clamp(32px, 4vw, 44px);
				margin: 0 0 8px;
				color: var(--accent);
			}

			.subtitle {
				margin: 0;
				color: var(--muted);
				font-size: 16px;
			}

			.meta {
				margin-top: 10px;
				font-size: 14px;
				color: var(--muted);
			}

			.grid {
				display: grid;
				grid-template-columns: repeat(3, minmax(0, 1fr));
				gap: 16px;
				margin: 28px 0 36px;
			}

			.card {
				background: var(--card);
				border: 1px solid var(--line);
				border-radius: 12px;
				padding: 16px;
				box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04);
			}

			.card span {
				display: block;
				font-size: 12px;
				text-transform: uppercase;
				letter-spacing: 0.08em;
				color: var(--muted);
				margin-bottom: 6px;
			}

			.card strong {
				font-size: 20px;
			}

			section {
				margin-bottom: 28px;
			}

			h2 {
				font-size: 20px;
				margin: 0 0 12px;
				color: var(--accent);
			}

			p {
				margin: 0 0 12px;
				color: var(--muted);
				line-height: 1.7;
			}

			ul {
				margin: 0;
				padding-left: 18px;
				color: var(--muted);
				line-height: 1.7;
			}

			table {
				width: 100%;
				border-collapse: collapse;
				margin-top: 12px;
				font-size: 14px;
			}

			th,
			td {
				text-align: left;
				padding: 10px 8px;
				border-bottom: 1px solid var(--line);
			}

			th {
				font-size: 12px;
				text-transform: uppercase;
				letter-spacing: 0.08em;
				color: var(--muted);
			}

			.highlight {
				font-weight: 600;
				color: var(--accent);
			}

			.code {
				font-family: "SFMono-Regular", ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas,
					"Liberation Mono", "Courier New", monospace;
				font-size: 12.5px;
				background: #f2f3f5;
				border-radius: 10px;
				border: 1px solid var(--line);
				padding: 14px;
				white-space: pre-wrap;
			}

			footer {
				border-top: 1px solid var(--line);
				margin-top: 36px;
				padding-top: 16px;
				font-size: 13px;
				color: var(--muted);
			}

			@media (max-width: 820px) {
				.grid {
					grid-template-columns: 1fr;
				}
			}
		</style>
	</head>
	<body>
		<main class="page">
			<header>
				<h1>Sports vs Politics Classifier</h1>
				<p class="subtitle">
					A concise evaluation of classic text classifiers on a focused 20 Newsgroups subset.
				</p>
				<div class="meta">Author: Anurag Samota (M25CE007)</div>
			</header>

			<section>
				<div class="grid">
					<div class="card">
						<span>Best Model</span>
						<strong>Naive Bayes</strong>
					</div>
					<div class="card">
						<span>Accuracy</span>
						<strong>0.9502</strong>
					</div>
					<div class="card">
						<span>Weighted F1</span>
						<strong>0.9499</strong>
					</div>
				</div>
			</section>

			<section>
				<h2>Overview</h2>
				<p>
					This project builds a binary classifier to separate sports from politics posts. The
					pipeline cleans the raw text, converts it to either Bag of Words or TF-IDF features, and
					compares three linear models on a stratified 70/30 split.
				</p>
				<ul>
					<li>Categories: rec.sport.baseball, rec.sport.hockey, talk.politics.*</li>
					<li>Samples: 4,618 total (Sports 1,993, Politics 2,625)</li>
					<li>Features: BoW and TF-IDF (unigrams + bigrams)</li>
				</ul>
			</section>

			<section>
				<h2>Results</h2>
				<table>
					<thead>
						<tr>
							<th>Model</th>
							<th>Features</th>
							<th>Accuracy</th>
							<th>Weighted F1</th>
						</tr>
					</thead>
					<tbody>
						<tr>
							<td>Naive Bayes</td>
							<td>BoW</td>
							<td class="highlight">0.9502</td>
							<td class="highlight">0.9499</td>
						</tr>
						<tr>
							<td>Logistic Regression</td>
							<td>TF-IDF (1-2 grams)</td>
							<td>0.9278</td>
							<td>0.9268</td>
						</tr>
						<tr>
							<td>Linear SVM</td>
							<td>TF-IDF (1-2 grams)</td>
							<td>0.9481</td>
							<td>0.9477</td>
						</tr>
					</tbody>
				</table>
			</section>

			<section>
				<h2>Class-Level Notes</h2>
				<ul>
					<li>BoW + Naive Bayes: Sports precision 0.98, recall 0.90; Politics precision 0.93, recall 0.99.</li>
					<li>TF-IDF + Linear SVM: Sports precision 0.99, recall 0.89; Politics precision 0.92, recall 0.99.</li>
					<li>Sports recall is slightly lower, suggesting overlap with political vocabulary.</li>
				</ul>
			</section>

			<section>
				<h2>Pipeline Snapshot</h2>
				<div class="code">
def normalize_text(raw_text):
		lowered = raw_text.lower()
		cleaned = re.sub(r'[^a-z\s]', ' ', lowered)
		compact = re.sub(r'\s+', ' ', cleaned)
		tokens = compact.strip().split()
		tokens = [tok for tok in tokens if len(tok) > 2]
		return " ".join(tokens)
				</div>
			</section>

			<section>
				<h2>Limitations and Next Steps</h2>
				<ul>
					<li>Dataset is narrow and may not reflect modern news or social media text.</li>
					<li>BoW and TF-IDF are surface-level features and miss deeper semantics.</li>
					<li>Try hyperparameter tuning or transformer embeddings for richer representations.</li>
				</ul>
			</section>

			<footer>
				Built from report.md and M25CSE007_prob4.py - February 2026
			</footer>
		</main>
	</body>
</html>
